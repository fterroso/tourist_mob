{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JupyterLab v3.2.4\r\n",
      "/home/fterroso/.local/share/jupyter/labextensions\r\n",
      "        @jupyter-widgets/jupyterlab-manager v3.1.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_widgets)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n",
      "3.8.10 (default, Nov 26 2021, 20:14:08) \n",
      "[GCC 9.3.0]\n",
      "sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pandas in /home/fterroso/.local/lib/python3.8/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy in /home/fterroso/.local/lib/python3.8/site-packages (1.22.3)\n",
      "Requirement already satisfied: tqdm in /home/fterroso/.local/lib/python3.8/site-packages (4.64.0)\n",
      "Requirement already satisfied: scikit-learn in /home/fterroso/.local/lib/python3.8/site-packages (1.0.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/fterroso/.local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/fterroso/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.0+cu113 in /home/fterroso/.local/lib/python3.8/site-packages (1.10.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /home/fterroso/.local/lib/python3.8/site-packages (from torch==1.10.0+cu113) (4.2.0)\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
      "Requirement already satisfied: torch-scatter in /home/fterroso/.local/lib/python3.8/site-packages (2.0.9)\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
      "Requirement already satisfied: torch-sparse in /home/fterroso/.local/lib/python3.8/site-packages (0.6.13)\n",
      "Requirement already satisfied: scipy in /home/fterroso/.local/lib/python3.8/site-packages (from torch-sparse) (1.8.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /home/fterroso/.local/lib/python3.8/site-packages (from scipy->torch-sparse) (1.22.3)\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: torch-geometric in /home/fterroso/.local/lib/python3.8/site-packages (2.0.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torch-geometric) (2.22.0)\n",
      "Requirement already satisfied: scipy in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.6)\n",
      "Requirement already satisfied: tqdm in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric) (4.64.0)\n",
      "Requirement already satisfied: pandas in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric) (1.3.5)\n",
      "Requirement already satisfied: numpy in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric) (1.22.3)\n",
      "Requirement already satisfied: scikit-learn in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric) (1.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/fterroso/.local/lib/python3.8/site-packages (from pandas->torch-geometric) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/fterroso/.local/lib/python3.8/site-packages (from pandas->torch-geometric) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.14.0)\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: torch-geometric-temporal in /home/fterroso/.local/lib/python3.8/site-packages (0.52.0)\n",
      "Requirement already satisfied: networkx in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (2.8)\n",
      "Requirement already satisfied: torch in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (1.10.0+cu113)\n",
      "Requirement already satisfied: tqdm in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (4.64.0)\n",
      "Requirement already satisfied: torch-scatter in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (2.0.9)\n",
      "Requirement already satisfied: torch-geometric in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (2.0.4)\n",
      "Requirement already satisfied: torch-sparse in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (0.6.13)\n",
      "Requirement already satisfied: numpy in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (1.22.3)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/lib/python3/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
      "Requirement already satisfied: pandas<=1.3.5 in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (1.3.5)\n",
      "Requirement already satisfied: scipy in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (1.8.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from torch-geometric-temporal) (1.14.0)\n",
      "Requirement already satisfied: cython in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric-temporal) (0.29.28)\n",
      "Requirement already satisfied: typing-extensions in /home/fterroso/.local/lib/python3.8/site-packages (from torch->torch-geometric-temporal) (4.2.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric->torch-geometric-temporal) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric->torch-geometric-temporal) (3.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/fterroso/.local/lib/python3.8/site-packages (from torch-geometric->torch-geometric-temporal) (1.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torch-geometric->torch-geometric-temporal) (2.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/fterroso/.local/lib/python3.8/site-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/fterroso/.local/lib/python3.8/site-packages (from pandas<=1.3.5->torch-geometric-temporal) (2022.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric->torch-geometric-temporal) (2.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric->torch-geometric-temporal) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fterroso/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric->torch-geometric-temporal) (3.1.0)\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: ipywidgets in /home/fterroso/.local/lib/python3.8/site-packages (7.7.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (6.5.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/fterroso/.local/lib/python3.8/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/lib/python3/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/lib/python3/dist-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /home/fterroso/.local/lib/python3.8/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.6)\n",
      "Requirement already satisfied: jupyter-core in /usr/lib/python3/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (45.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.22)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.6.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/fterroso/.local/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /usr/lib/python3/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.9)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy tqdm scikit-learn\n",
    "\n",
    "!pip install torch==1.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
    "!pip install torch-geometric\n",
    "!pip install torch-geometric-temporal\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.data import Data, Dataset\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU, GCLSTM, DCRNN, A3TGCN\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#for local environment\n",
    "data_path= os.path.join('data', 'mobility')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.3'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import tourist_mobility3\n",
    "reload(tourist_mobility3)\n",
    "from tourist_mobility3 import TouristMobDynamicDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'graph_datasets', 'node_to_codes_all_data_dynamic.json')) as f:\n",
    "     nodes_to_code= json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': '01001_AM',\n",
       " '1': '01002',\n",
       " '2': '01010_AM',\n",
       " '3': '01031_AM',\n",
       " '4': '01036',\n",
       " '5': '01043_AM',\n",
       " '6': '01047_AM',\n",
       " '7': '01051',\n",
       " '8': '01058_AM',\n",
       " '9': '01059',\n",
       " '10': '01063_AM',\n",
       " '11': '01901_AM',\n",
       " '12': '02003',\n",
       " '13': '02008_AM',\n",
       " '14': '02009',\n",
       " '15': '02010_AM',\n",
       " '16': '02012_AM',\n",
       " '17': '02021_AM',\n",
       " '18': '02024_AM',\n",
       " '19': '02025',\n",
       " '20': '02029_AM',\n",
       " '21': '02030_AM',\n",
       " '22': '02033_AM',\n",
       " '23': '02037',\n",
       " '24': '02045_AM',\n",
       " '25': '02053_AM',\n",
       " '26': '02063_AM',\n",
       " '27': '02067_AM',\n",
       " '28': '02069_AM',\n",
       " '29': '02073_AM',\n",
       " '30': '02074',\n",
       " '31': '02079_AM',\n",
       " '32': '02081',\n",
       " '33': '02086_AM',\n",
       " '34': '03002_AM',\n",
       " '35': '03005_AM',\n",
       " '36': '03009',\n",
       " '37': '03011',\n",
       " '38': '03014',\n",
       " '39': '03015',\n",
       " '40': '03018',\n",
       " '41': '03019',\n",
       " '42': '03021',\n",
       " '43': '03024',\n",
       " '44': '03028_AM',\n",
       " '45': '03031',\n",
       " '46': '03041',\n",
       " '47': '03043_AM',\n",
       " '48': '03046_AM',\n",
       " '49': '03047',\n",
       " '50': '03048',\n",
       " '51': '03049',\n",
       " '52': '03050',\n",
       " '53': '03053',\n",
       " '54': '03055',\n",
       " '55': '03056',\n",
       " '56': '03058_AM',\n",
       " '57': '03059',\n",
       " '58': '03063',\n",
       " '59': '03065',\n",
       " '60': '03066',\n",
       " '61': '03069',\n",
       " '62': '03070_AM',\n",
       " '63': '03071',\n",
       " '64': '03076',\n",
       " '65': '03077_AM',\n",
       " '66': '03079',\n",
       " '67': '03081_AM',\n",
       " '68': '03082',\n",
       " '69': '03083',\n",
       " '70': '03088',\n",
       " '71': '03089',\n",
       " '72': '03090',\n",
       " '73': '03092_AM',\n",
       " '74': '03093',\n",
       " '75': '03094',\n",
       " '76': '03095',\n",
       " '77': '03096',\n",
       " '78': '03097_AM',\n",
       " '79': '03099',\n",
       " '80': '03101',\n",
       " '81': '03102',\n",
       " '82': '03104',\n",
       " '83': '03105',\n",
       " '84': '03107',\n",
       " '85': '03109',\n",
       " '86': '03111',\n",
       " '87': '03113',\n",
       " '88': '03118',\n",
       " '89': '03119',\n",
       " '90': '03121',\n",
       " '91': '03122',\n",
       " '92': '03123_AM',\n",
       " '93': '03128_AM',\n",
       " '94': '03133',\n",
       " '95': '03138_AM',\n",
       " '96': '03139',\n",
       " '97': '03140',\n",
       " '98': '03902',\n",
       " '99': '03903_AM',\n",
       " '100': '04003',\n",
       " '101': '04006',\n",
       " '102': '04011_AM',\n",
       " '103': '04013',\n",
       " '104': '04016_AM',\n",
       " '105': '04017_AM',\n",
       " '106': '04024_AM',\n",
       " '107': '04029',\n",
       " '108': '04031_AM',\n",
       " '109': '04032',\n",
       " '110': '04035',\n",
       " '111': '04038_AM',\n",
       " '112': '04045_AM',\n",
       " '113': '04047_AM',\n",
       " '114': '04049',\n",
       " '115': '04050_AM',\n",
       " '116': '04052',\n",
       " '117': '04053',\n",
       " '118': '04057_AM',\n",
       " '119': '04064',\n",
       " '120': '04066',\n",
       " '121': '04070_AM',\n",
       " '122': '04075',\n",
       " '123': '04079',\n",
       " '124': '04088_AM',\n",
       " '125': '04092_AM',\n",
       " '126': '04093_AM',\n",
       " '127': '04098_AM',\n",
       " '128': '04099',\n",
       " '129': '04100',\n",
       " '130': '04101',\n",
       " '131': '04102',\n",
       " '132': '0490201',\n",
       " '133': '04903',\n",
       " '134': '05002_AM',\n",
       " '135': '05016',\n",
       " '136': '05019',\n",
       " '137': '05021_AM',\n",
       " '138': '05047',\n",
       " '139': '05057_AM',\n",
       " '140': '05114_AM',\n",
       " '141': '05168_AM',\n",
       " '142': '05186_AM',\n",
       " '143': '05204_AM',\n",
       " '144': '05238_AM',\n",
       " '145': '05241_AM',\n",
       " '146': '05242_AM',\n",
       " '147': '06002',\n",
       " '148': '06005_AM',\n",
       " '149': '06006',\n",
       " '150': '06011',\n",
       " '151': '06012_AM',\n",
       " '152': '06014_AM',\n",
       " '153': '06015',\n",
       " '154': '06016_AM',\n",
       " '155': '06019_AM',\n",
       " '156': '06022_AM',\n",
       " '157': '06023_AM',\n",
       " '158': '06025',\n",
       " '159': '06028_AM',\n",
       " '160': '06036_AM',\n",
       " '161': '06044_AM',\n",
       " '162': '06050_AM',\n",
       " '163': '06052_AM',\n",
       " '164': '06054',\n",
       " '165': '06055_AM',\n",
       " '166': '06060_AM',\n",
       " '167': '06063_AM',\n",
       " '168': '06066_AM',\n",
       " '169': '06069_AM',\n",
       " '170': '06070_AM',\n",
       " '171': '06072_AM',\n",
       " '172': '06074_AM',\n",
       " '173': '06083',\n",
       " '174': '06085_AM',\n",
       " '175': '06088_AM',\n",
       " '176': '06091_AM',\n",
       " '177': '06093_AM',\n",
       " '178': '06094_AM',\n",
       " '179': '06095_AM',\n",
       " '180': '06103',\n",
       " '181': '06108_AM',\n",
       " '182': '06109_AM',\n",
       " '183': '06113_AM',\n",
       " '184': '06117_AM',\n",
       " '185': '06120_AM',\n",
       " '186': '06121_AM',\n",
       " '187': '06122',\n",
       " '188': '06123_AM',\n",
       " '189': '06125_AM',\n",
       " '190': '06127_AM',\n",
       " '191': '06128_AM',\n",
       " '192': '06149',\n",
       " '193': '06153',\n",
       " '194': '06154_AM',\n",
       " '195': '06155_AM',\n",
       " '196': '06158',\n",
       " '197': '06162_AM',\n",
       " '198': '07003',\n",
       " '199': '07005',\n",
       " '200': '07011',\n",
       " '201': '07015',\n",
       " '202': '07022',\n",
       " '203': '07024',\n",
       " '204': '07026',\n",
       " '205': '07031',\n",
       " '206': '07032',\n",
       " '207': '07036',\n",
       " '208': '07037',\n",
       " '209': '07039',\n",
       " '210': '07040',\n",
       " '211': '07042',\n",
       " '212': '07045_AM',\n",
       " '213': '07046',\n",
       " '214': '07048',\n",
       " '215': '07050',\n",
       " '216': '07052',\n",
       " '217': '07054',\n",
       " '218': '07055',\n",
       " '219': '07056',\n",
       " '220': '07058_AM',\n",
       " '221': '08001',\n",
       " '222': '08003',\n",
       " '223': '08005',\n",
       " '224': '08006',\n",
       " '225': '08007',\n",
       " '226': '08009',\n",
       " '227': '08010_AM',\n",
       " '228': '08014_AM',\n",
       " '229': '08015',\n",
       " '230': '08016_AM',\n",
       " '231': '08017_AM',\n",
       " '232': '08019',\n",
       " '233': '08022',\n",
       " '234': '08023',\n",
       " '235': '08029',\n",
       " '236': '08031_AM',\n",
       " '237': '08033',\n",
       " '238': '08037_AM',\n",
       " '239': '08040',\n",
       " '240': '08041',\n",
       " '241': '08043_AM',\n",
       " '242': '08044_AM',\n",
       " '243': '08047_AM',\n",
       " '244': '08051_AM',\n",
       " '245': '08053_AM',\n",
       " '246': '08054',\n",
       " '247': '08056',\n",
       " '248': '08064_AM',\n",
       " '249': '08067',\n",
       " '250': '08068_AM',\n",
       " '251': '08069',\n",
       " '252': '08072',\n",
       " '253': '08073',\n",
       " '254': '08074',\n",
       " '255': '08075',\n",
       " '256': '08076',\n",
       " '257': '08077',\n",
       " '258': '08085_AM',\n",
       " '259': '08086',\n",
       " '260': '08089',\n",
       " '261': '08091_AM',\n",
       " '262': '08092_AM',\n",
       " '263': '08094_AM',\n",
       " '264': '08096',\n",
       " '265': '08100_AM',\n",
       " '266': '08101',\n",
       " '267': '08102',\n",
       " '268': '08105',\n",
       " '269': '08106',\n",
       " '270': '08107',\n",
       " '271': '08108',\n",
       " '272': '08110',\n",
       " '273': '08112',\n",
       " '274': '08113',\n",
       " '275': '08114',\n",
       " '276': '08115_AM',\n",
       " '277': '08118',\n",
       " '278': '08119',\n",
       " '279': '08121',\n",
       " '280': '08122_AM',\n",
       " '281': '08123',\n",
       " '282': '08124',\n",
       " '283': '08125',\n",
       " '284': '08126',\n",
       " '285': '08135',\n",
       " '286': '08136',\n",
       " '287': '08138',\n",
       " '288': '08141',\n",
       " '289': '08143_AM',\n",
       " '290': '08145_AM',\n",
       " '291': '08147',\n",
       " '292': '08155_AM',\n",
       " '293': '08156',\n",
       " '294': '08157',\n",
       " '295': '08158',\n",
       " '296': '08159',\n",
       " '297': '08161',\n",
       " '298': '08162_AM',\n",
       " '299': '08163',\n",
       " '300': '08167',\n",
       " '301': '08169',\n",
       " '302': '08171_AM',\n",
       " '303': '08172',\n",
       " '304': '08175_AM',\n",
       " '305': '08180',\n",
       " '306': '08181',\n",
       " '307': '08182',\n",
       " '308': '08184',\n",
       " '309': '08187',\n",
       " '310': '08191',\n",
       " '311': '08194',\n",
       " '312': '08196',\n",
       " '313': '08197',\n",
       " '314': '08198',\n",
       " '315': '08200',\n",
       " '316': '08202',\n",
       " '317': '08203_AM',\n",
       " '318': '08205',\n",
       " '319': '08208_AM',\n",
       " '320': '08209',\n",
       " '321': '08211',\n",
       " '322': '08213',\n",
       " '323': '08215_AM',\n",
       " '324': '08217',\n",
       " '325': '08218_AM',\n",
       " '326': '08220_AM',\n",
       " '327': '08221',\n",
       " '328': '08227_AM',\n",
       " '329': '08231',\n",
       " '330': '08232_AM',\n",
       " '331': '08233_AM',\n",
       " '332': '08237_AM',\n",
       " '333': '08238',\n",
       " '334': '08240',\n",
       " '335': '08244',\n",
       " '336': '08245',\n",
       " '337': '08248',\n",
       " '338': '08251',\n",
       " '339': '08252',\n",
       " '340': '08260',\n",
       " '341': '08262_AM',\n",
       " '342': '08263',\n",
       " '343': '08266',\n",
       " '344': '08267',\n",
       " '345': '08269_AM',\n",
       " '346': '08270',\n",
       " '347': '08273_AM',\n",
       " '348': '08274',\n",
       " '349': '08278_AM',\n",
       " '350': '08279',\n",
       " '351': '08281',\n",
       " '352': '08282',\n",
       " '353': '08283',\n",
       " '354': '08284_AM',\n",
       " '355': '08285',\n",
       " '356': '08286_AM',\n",
       " '357': '08288_AM',\n",
       " '358': '08291',\n",
       " '359': '08295',\n",
       " '360': '08298',\n",
       " '361': '08300_AM',\n",
       " '362': '08301',\n",
       " '363': '08305',\n",
       " '364': '08307',\n",
       " '365': '08902_AM',\n",
       " '366': '08904',\n",
       " '367': '09018',\n",
       " '368': '09048_AM',\n",
       " '369': '09056',\n",
       " '370': '09059',\n",
       " '371': '09109_AM',\n",
       " '372': '09141_AM',\n",
       " '373': '09174_AM',\n",
       " '374': '09177_AM',\n",
       " '375': '09194_AM',\n",
       " '376': '09209_AM',\n",
       " '377': '09211_AM',\n",
       " '378': '09219',\n",
       " '379': '09238_AM',\n",
       " '380': '09289_AM',\n",
       " '381': '09321_AM',\n",
       " '382': '09330_AM',\n",
       " '383': '09350_AM',\n",
       " '384': '09363_AM',\n",
       " '385': '09410',\n",
       " '386': '09413_AM',\n",
       " '387': '09434_AM',\n",
       " '388': '09439_AM',\n",
       " '389': '09903_AM',\n",
       " '390': '09907_AM',\n",
       " '391': '10006_AM',\n",
       " '392': '10010_AM',\n",
       " '393': '10018_AM',\n",
       " '394': '10019_AM',\n",
       " '395': '10020_AM',\n",
       " '396': '10037',\n",
       " '397': '10049_AM',\n",
       " '398': '10050_AM',\n",
       " '399': '10061_AM',\n",
       " '400': '10064_AM',\n",
       " '401': '10067',\n",
       " '402': '10089_AM',\n",
       " '403': '10096_AM',\n",
       " '404': '10104',\n",
       " '405': '10105_AM',\n",
       " '406': '10109_AM',\n",
       " '407': '10110_AM',\n",
       " '408': '10113_AM',\n",
       " '409': '10115',\n",
       " '410': '10116_AM',\n",
       " '411': '10121',\n",
       " '412': '10127',\n",
       " '413': '10128',\n",
       " '414': '10131',\n",
       " '415': '10140_AM',\n",
       " '416': '10146_AM',\n",
       " '417': '10147_AM',\n",
       " '418': '10148',\n",
       " '419': '10175_AM',\n",
       " '420': '10177_AM',\n",
       " '421': '10180_AM',\n",
       " '422': '10184_AM',\n",
       " '423': '10186_AM',\n",
       " '424': '10189_AM',\n",
       " '425': '10195_AM',\n",
       " '426': '10203',\n",
       " '427': '10205_AM',\n",
       " '428': '10212_AM',\n",
       " '429': '10216_AM',\n",
       " '430': '11001',\n",
       " '431': '11002_AM',\n",
       " '432': '11004',\n",
       " '433': '11006',\n",
       " '434': '11007',\n",
       " '435': '11008',\n",
       " '436': '11010_AM',\n",
       " '437': '11011_AM',\n",
       " '438': '11012',\n",
       " '439': '11014',\n",
       " '440': '11015',\n",
       " '441': '11016',\n",
       " '442': '11020',\n",
       " '443': '11021_AM',\n",
       " '444': '11022',\n",
       " '445': '11023',\n",
       " '446': '11024_AM',\n",
       " '447': '11026_AM',\n",
       " '448': '11027',\n",
       " '449': '11028',\n",
       " '450': '11029',\n",
       " '451': '11030',\n",
       " '452': '11031',\n",
       " '453': '11032',\n",
       " '454': '11033',\n",
       " '455': '11035',\n",
       " '456': '11037',\n",
       " '457': '11038',\n",
       " '458': '11039',\n",
       " '459': '11041',\n",
       " '460': '11901',\n",
       " '461': '11902_AM',\n",
       " '462': '12004',\n",
       " '463': '12005',\n",
       " '464': '12009',\n",
       " '465': '12011_AM',\n",
       " '466': '12012_AM',\n",
       " '467': '12016_AM',\n",
       " '468': '12021',\n",
       " '469': '12027',\n",
       " '470': '12028',\n",
       " '471': '12031_AM',\n",
       " '472': '12032',\n",
       " '473': '12033_AM',\n",
       " '474': '12040',\n",
       " '475': '12050_AM',\n",
       " '476': '12072_AM',\n",
       " '477': '12077_AM',\n",
       " '478': '12080_AM',\n",
       " '479': '12082_AM',\n",
       " '480': '12084',\n",
       " '481': '12085',\n",
       " '482': '12089',\n",
       " '483': '12100_AM',\n",
       " '484': '12104',\n",
       " '485': '12106_AM',\n",
       " '486': '12117',\n",
       " '487': '12121_AM',\n",
       " '488': '12124_AM',\n",
       " '489': '12126',\n",
       " '490': '12129_AM',\n",
       " '491': '12135',\n",
       " '492': '12138',\n",
       " '493': '12140_AM',\n",
       " '494': '12901',\n",
       " '495': '13005',\n",
       " '496': '13011',\n",
       " '497': '13013_AM',\n",
       " '498': '13015',\n",
       " '499': '13019',\n",
       " '500': '13020_AM',\n",
       " '501': '13023',\n",
       " '502': '13027_AM',\n",
       " '503': '13028_AM',\n",
       " '504': '13031_AM',\n",
       " '505': '13034',\n",
       " '506': '13038_AM',\n",
       " '507': '13039',\n",
       " '508': '13042_AM',\n",
       " '509': '13044_AM',\n",
       " '510': '13047',\n",
       " '511': '13052',\n",
       " '512': '13053_AM',\n",
       " '513': '13054',\n",
       " '514': '13056',\n",
       " '515': '13058',\n",
       " '516': '13061',\n",
       " '517': '13063_AM',\n",
       " '518': '13064_AM',\n",
       " '519': '13065_AM',\n",
       " '520': '13068_AM',\n",
       " '521': '13071',\n",
       " '522': '13077_AM',\n",
       " '523': '13078',\n",
       " '524': '13079',\n",
       " '525': '13082',\n",
       " '526': '13085_AM',\n",
       " '527': '13087',\n",
       " '528': '13089_AM',\n",
       " '529': '13092_AM',\n",
       " '530': '13093_AM',\n",
       " '531': '13096',\n",
       " '532': '13097_AM',\n",
       " '533': '14001_AM',\n",
       " '534': '14002',\n",
       " '535': '14005_AM',\n",
       " '536': '14007_AM',\n",
       " '537': '14008_AM',\n",
       " '538': '14009_AM',\n",
       " '539': '14010_AM',\n",
       " '540': '14012_AM',\n",
       " '541': '14013',\n",
       " '542': '14017',\n",
       " '543': '14019',\n",
       " '544': '14021',\n",
       " '545': '14022_AM',\n",
       " '546': '14023_AM',\n",
       " '547': '14027',\n",
       " '548': '14029_AM',\n",
       " '549': '14030_AM',\n",
       " '550': '14035',\n",
       " '551': '14038',\n",
       " '552': '14039_AM',\n",
       " '553': '14041_AM',\n",
       " '554': '14042',\n",
       " '555': '14043_AM',\n",
       " '556': '14045_AM',\n",
       " '557': '14046',\n",
       " '558': '14049',\n",
       " '559': '14052',\n",
       " '560': '14053_AM',\n",
       " '561': '14054',\n",
       " '562': '14055_AM',\n",
       " '563': '14056',\n",
       " '564': '14057_AM',\n",
       " '565': '14058_AM',\n",
       " '566': '14060_AM',\n",
       " '567': '14066',\n",
       " '568': '14067_AM',\n",
       " '569': '14069_AM',\n",
       " '570': '14073_AM',\n",
       " '571': '15001',\n",
       " '572': '15002',\n",
       " '573': '15004',\n",
       " '574': '15005',\n",
       " '575': '15006_AM',\n",
       " '576': '15008',\n",
       " '577': '15009',\n",
       " '578': '15010_AM',\n",
       " '579': '15011',\n",
       " '580': '15012_AM',\n",
       " '581': '15013',\n",
       " '582': '15014_AM',\n",
       " '583': '15017',\n",
       " '584': '15019',\n",
       " '585': '15020_AM',\n",
       " '586': '15021',\n",
       " '587': '15022_AM',\n",
       " '588': '15024_AM',\n",
       " '589': '15029',\n",
       " '590': '15030',\n",
       " '591': '15031',\n",
       " '592': '15032_AM',\n",
       " '593': '15035_AM',\n",
       " '594': '15036',\n",
       " '595': '15041',\n",
       " '596': '15043',\n",
       " '597': '15046',\n",
       " '598': '15047_AM',\n",
       " '599': '15048',\n",
       " '600': '15050_AM',\n",
       " '601': '15051',\n",
       " '602': '15053',\n",
       " '603': '15054',\n",
       " '604': '15055_AM',\n",
       " '605': '15056',\n",
       " '606': '15057',\n",
       " '607': '15058',\n",
       " '608': '15059',\n",
       " '609': '15060',\n",
       " '610': '15061_AM',\n",
       " '611': '15064_AM',\n",
       " '612': '15066',\n",
       " '613': '15067',\n",
       " '614': '15068',\n",
       " '615': '15069',\n",
       " '616': '15070_AM',\n",
       " '617': '15071',\n",
       " '618': '15072',\n",
       " '619': '15073',\n",
       " '620': '15074_AM',\n",
       " '621': '15075',\n",
       " '622': '15077',\n",
       " '623': '15078',\n",
       " '624': '15082',\n",
       " '625': '15087',\n",
       " '626': '15088_AM',\n",
       " '627': '15089',\n",
       " '628': '15092',\n",
       " '629': '15093',\n",
       " '630': '15902',\n",
       " '631': '16023_AM',\n",
       " '632': '16027_AM',\n",
       " '633': '16042_AM',\n",
       " '634': '16066_AM',\n",
       " '635': '16078',\n",
       " '636': '16102_AM',\n",
       " '637': '16106_AM',\n",
       " '638': '16112_AM',\n",
       " '639': '16113_AM',\n",
       " '640': '16117_AM',\n",
       " '641': '16124_AM',\n",
       " '642': '16125_AM',\n",
       " '643': '16133',\n",
       " '644': '16154',\n",
       " '645': '16171_AM',\n",
       " '646': '16175',\n",
       " '647': '16190',\n",
       " '648': '16191_AM',\n",
       " '649': '16203',\n",
       " '650': '16249_AM',\n",
       " '651': '16251_AM',\n",
       " '652': '16903_AM',\n",
       " '653': '16905_AM',\n",
       " '654': '17006_AM',\n",
       " '655': '17007_AM',\n",
       " '656': '17012_AM',\n",
       " '657': '17013_AM',\n",
       " '658': '17015',\n",
       " '659': '17016_AM',\n",
       " '660': '17019_AM',\n",
       " '661': '17020_AM',\n",
       " '662': '17032_AM',\n",
       " '663': '17033',\n",
       " '664': '17034',\n",
       " '665': '17036_AM',\n",
       " '666': '17039_AM',\n",
       " '667': '17044',\n",
       " '668': '17047',\n",
       " '669': '17056_AM',\n",
       " '670': '17062',\n",
       " '671': '17066',\n",
       " '672': '17067_AM',\n",
       " '673': '17079',\n",
       " '674': '17083_AM',\n",
       " '675': '17086_AM',\n",
       " '676': '17095',\n",
       " '677': '17103',\n",
       " '678': '17111_AM',\n",
       " '679': '17114',\n",
       " '680': '17117',\n",
       " '681': '17118',\n",
       " '682': '17132_AM',\n",
       " '683': '17137_AM',\n",
       " '684': '17141',\n",
       " '685': '17142_AM',\n",
       " '686': '17146_AM',\n",
       " '687': '17147',\n",
       " '688': '17152',\n",
       " '689': '17155',\n",
       " '690': '17163_AM',\n",
       " '691': '17164_AM',\n",
       " '692': '17178_AM',\n",
       " '693': '17180_AM',\n",
       " '694': '17181',\n",
       " '695': '17185_AM',\n",
       " '696': '17186',\n",
       " '697': '17193',\n",
       " '698': '17199',\n",
       " '699': '17207_AM',\n",
       " '700': '17211_AM',\n",
       " '701': '17213',\n",
       " '702': '17221',\n",
       " '703': '17223_AM',\n",
       " '704': '17233_AM',\n",
       " '705': '17901_AM',\n",
       " '706': '18003',\n",
       " '707': '18006',\n",
       " '708': '18011_AM',\n",
       " '709': '18013_AM',\n",
       " '710': '18014_AM',\n",
       " '711': '18017',\n",
       " '712': '18021',\n",
       " '713': '18022',\n",
       " '714': '18023',\n",
       " '715': '18027_AM',\n",
       " '716': '18029_AM',\n",
       " '717': '18036',\n",
       " '718': '18047',\n",
       " '719': '18056_AM',\n",
       " '720': '18057',\n",
       " '721': '18059',\n",
       " '722': '18061_AM',\n",
       " '723': '18062',\n",
       " '724': '18063_AM',\n",
       " '725': '18066_AM',\n",
       " '726': '18079_AM',\n",
       " '727': '18084',\n",
       " '728': '18087',\n",
       " '729': '18088_AM',\n",
       " '730': '18089',\n",
       " '731': '18093',\n",
       " '732': '18094_AM',\n",
       " '733': '18098',\n",
       " '734': '18099_AM',\n",
       " '735': '18100',\n",
       " '736': '18101',\n",
       " '737': '18102_AM',\n",
       " '738': '18105',\n",
       " '739': '18108_AM',\n",
       " '740': '18116_AM',\n",
       " '741': '18119_AM',\n",
       " '742': '18122_AM',\n",
       " '743': '18127',\n",
       " '744': '18132_AM',\n",
       " '745': '18133_AM',\n",
       " '746': '18134',\n",
       " '747': '18135_AM',\n",
       " '748': '18136_AM',\n",
       " '749': '18138_AM',\n",
       " '750': '18140',\n",
       " '751': '18145',\n",
       " '752': '18149_AM',\n",
       " '753': '18150',\n",
       " '754': '18152_AM',\n",
       " '755': '18153',\n",
       " '756': '18158',\n",
       " '757': '18162_AM',\n",
       " '758': '18164_AM',\n",
       " '759': '18165',\n",
       " '760': '18173',\n",
       " '761': '18175',\n",
       " '762': '18182_AM',\n",
       " '763': '18184_AM',\n",
       " '764': '18193',\n",
       " '765': '18194_AM',\n",
       " '766': '18905',\n",
       " '767': '18907_AM',\n",
       " '768': '18911',\n",
       " '769': '19024',\n",
       " '770': '19046_AM',\n",
       " '771': '19053_AM',\n",
       " '772': '19058_AM',\n",
       " '773': '19086_AM',\n",
       " '774': '19130',\n",
       " '775': '19151_AM',\n",
       " '776': '19156_AM',\n",
       " '777': '19160_AM',\n",
       " '778': '19171',\n",
       " '779': '19190_AM',\n",
       " '780': '19192_AM',\n",
       " '781': '19245_AM',\n",
       " '782': '19257_AM',\n",
       " '783': '19274_AM',\n",
       " '784': '19319',\n",
       " '785': '19326_AM',\n",
       " '786': '19331_AM',\n",
       " '787': '20005_AM',\n",
       " '788': '20009',\n",
       " '789': '20010_AM',\n",
       " '790': '20017',\n",
       " '791': '20018',\n",
       " '792': '20022_AM',\n",
       " '793': '20025_AM',\n",
       " '794': '20027_AM',\n",
       " '795': '20028_AM',\n",
       " '796': '20029',\n",
       " '797': '20030',\n",
       " '798': '20032',\n",
       " '799': '20034_AM',\n",
       " '800': '20036',\n",
       " '801': '20039_AM',\n",
       " '802': '20040',\n",
       " '803': '20042',\n",
       " '804': '20043_AM',\n",
       " '805': '20045',\n",
       " '806': '20052_AM',\n",
       " '807': '20053',\n",
       " '808': '20055',\n",
       " '809': '20056_AM',\n",
       " '810': '20059',\n",
       " '811': '20063',\n",
       " '812': '20064',\n",
       " '813': '20067',\n",
       " '814': '20069',\n",
       " '815': '20071',\n",
       " '816': '20072',\n",
       " '817': '20073',\n",
       " '818': '20074_AM',\n",
       " '819': '20075',\n",
       " '820': '20076',\n",
       " '821': '20077_AM',\n",
       " '822': '20079',\n",
       " '823': '20080',\n",
       " '824': '20081',\n",
       " '825': '20902',\n",
       " '826': '21002',\n",
       " '827': '21005',\n",
       " '828': '21006_AM',\n",
       " '829': '21008_AM',\n",
       " '830': '21010_AM',\n",
       " '831': '21011',\n",
       " '832': '21013',\n",
       " '833': '21014_AM',\n",
       " '834': '21021',\n",
       " '835': '21023_AM',\n",
       " '836': '21025',\n",
       " '837': '21029_AM',\n",
       " '838': '21035_AM',\n",
       " '839': '21040_AM',\n",
       " '840': '21041',\n",
       " '841': '21042',\n",
       " '842': '21043_AM',\n",
       " '843': '21044',\n",
       " '844': '21049_AM',\n",
       " '845': '21050',\n",
       " '846': '21052_AM',\n",
       " '847': '21053_AM',\n",
       " '848': '21054',\n",
       " '849': '21055',\n",
       " '850': '21056_AM',\n",
       " '851': '21058_AM',\n",
       " '852': '21060',\n",
       " '853': '21061',\n",
       " '854': '21064',\n",
       " '855': '21069_AM',\n",
       " '856': '21070',\n",
       " '857': '21072',\n",
       " '858': '21074_AM',\n",
       " '859': '21076_AM',\n",
       " '860': '22017_AM',\n",
       " '861': '22021_AM',\n",
       " '862': '22039_AM',\n",
       " '863': '22048',\n",
       " '864': '22053_AM',\n",
       " '865': '22060_AM',\n",
       " '866': '22061',\n",
       " '867': '22084_AM',\n",
       " '868': '22112_AM',\n",
       " '869': '22116_AM',\n",
       " '870': '22117_AM',\n",
       " '871': '22125',\n",
       " '872': '22130',\n",
       " '873': '22137_AM',\n",
       " '874': '22158',\n",
       " '875': '22199',\n",
       " '876': '22204_AM',\n",
       " '877': '22213_AM',\n",
       " '878': '22225_AM',\n",
       " '879': '22228_AM',\n",
       " '880': '22254_AM',\n",
       " '881': '22901_AM',\n",
       " '882': '22907_AM',\n",
       " '883': '23002',\n",
       " '884': '23003',\n",
       " '885': '23005',\n",
       " '886': '23006_AM',\n",
       " '887': '23009',\n",
       " '888': '23010',\n",
       " '889': '23012_AM',\n",
       " '890': '23014_AM',\n",
       " '891': '23018_AM',\n",
       " '892': '23024',\n",
       " '893': '23025_AM',\n",
       " '894': '23026_AM',\n",
       " '895': '23028',\n",
       " '896': '23038',\n",
       " '897': '23039_AM',\n",
       " '898': '23044_AM',\n",
       " '899': '23050',\n",
       " '900': '23053',\n",
       " '901': '23055',\n",
       " '902': '23058',\n",
       " '903': '23059_AM',\n",
       " '904': '23061_AM',\n",
       " '905': '23063_AM',\n",
       " '906': '23066',\n",
       " '907': '23067_AM',\n",
       " '908': '23069_AM',\n",
       " '909': '23070_AM',\n",
       " '910': '23073_AM',\n",
       " '911': '23074_AM',\n",
       " '912': '23079_AM',\n",
       " '913': '23082_AM',\n",
       " '914': '23086_AM',\n",
       " '915': '23087',\n",
       " '916': '23088_AM',\n",
       " '917': '23092',\n",
       " '918': '23093_AM',\n",
       " '919': '23094_AM',\n",
       " '920': '23095',\n",
       " '921': '23096_AM',\n",
       " '922': '23097_AM',\n",
       " '923': '23902_AM',\n",
       " '924': '23904_AM',\n",
       " '925': '23905_AM',\n",
       " '926': '24008',\n",
       " '927': '24010',\n",
       " '928': '24014',\n",
       " '929': '24015_AM',\n",
       " '930': '24021_AM',\n",
       " '931': '24030',\n",
       " '932': '24034_AM',\n",
       " '933': '24038_AM',\n",
       " '934': '24039_AM',\n",
       " '935': '24056_AM',\n",
       " '936': '24065_AM',\n",
       " '937': '24083_AM',\n",
       " '938': '24088_AM',\n",
       " '939': '24089',\n",
       " '940': '24092_AM',\n",
       " '941': '24094_AM',\n",
       " '942': '24115',\n",
       " '943': '24122_AM',\n",
       " '944': '24134_AM',\n",
       " '945': '24139_AM',\n",
       " '946': '24142',\n",
       " '947': '24148_AM',\n",
       " '948': '24154_AM',\n",
       " '949': '24157_AM',\n",
       " '950': '24160_AM',\n",
       " '951': '24163_AM',\n",
       " '952': '24169_AM',\n",
       " '953': '24170_AM',\n",
       " '954': '24175_AM',\n",
       " '955': '24181_AM',\n",
       " '956': '24188',\n",
       " '957': '24189',\n",
       " '958': '24196_AM',\n",
       " '959': '24202',\n",
       " '960': '24209_AM',\n",
       " '961': '24212_AM',\n",
       " '962': '24222',\n",
       " '963': '24223_AM',\n",
       " '964': '25003',\n",
       " '965': '25007_AM',\n",
       " '966': '25008_AM',\n",
       " '967': '25011_AM',\n",
       " '968': '25012_AM',\n",
       " '969': '25019',\n",
       " '970': '25021_AM',\n",
       " '971': '25023',\n",
       " '972': '25025_AM',\n",
       " '973': '25029_AM',\n",
       " '974': '25033_AM',\n",
       " '975': '25034_AM',\n",
       " '976': '25038_AM',\n",
       " '977': '25040',\n",
       " '978': '25048_AM',\n",
       " '979': '25050',\n",
       " '980': '25051_AM',\n",
       " '981': '25058',\n",
       " '982': '25062_AM',\n",
       " '983': '25072',\n",
       " '984': '25099_AM',\n",
       " '985': '25110',\n",
       " '986': '25113_AM',\n",
       " '987': '25119_AM',\n",
       " '988': '25120',\n",
       " '989': '25122_AM',\n",
       " '990': '25137',\n",
       " '991': '25158_AM',\n",
       " '992': '25172_AM',\n",
       " '993': '25173_AM',\n",
       " '994': '25189_AM',\n",
       " '995': '25192_AM',\n",
       " '996': '25193_AM',\n",
       " '997': '25203',\n",
       " '998': '25204_AM',\n",
       " '999': '25207',\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent1 = A3TGCN(in_channels=node_features, out_channels=128, periods=periods) # node_features=4, periods=7\n",
    "        self.linear1 = torch.nn.Linear(128, 128)\n",
    "        self.dropout = torch.nn.Dropout(0.25)    \n",
    "        self.linear2 = torch.nn.Linear(128, 128)\n",
    "\n",
    "        self.linear3 = torch.nn.Linear(128, 8)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h):\n",
    "        #print(x.shape, edge_index.shape, edge_weight.shape)\n",
    "        h_0= self.recurrent1(x, edge_index, edge_weight, h)\n",
    "        h = F.relu(h_0)\n",
    "        \n",
    "        h = self.linear1(h)\n",
    "        h = F.relu(h)\n",
    "\n",
    "        h = self.linear2(h)\n",
    "        h = F.relu(h)\n",
    "        #h2= self.linear2(torch.Tensor(x[1]))\n",
    "        #h3 = torch.cat((h1, h2), dim=1)\n",
    "        h= self.dropout(h)\n",
    "        h = self.linear3(h)\n",
    "        #print(self.linear3.weight.grad)\n",
    "\n",
    "        return h, h_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_negative_edges(positive_edges, nodes_to_code, n_samples):\n",
    "    \n",
    "    edges_= np.vstack((positive_edges[0].cpu(),positive_edges[1].cpu())).T\n",
    "    \n",
    "    origins = []\n",
    "    dest = []\n",
    "    #Here we generate a negative link for each node in the snapshot\n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        o_node= np.random.randint(len(nodes_to_code.keys()))\n",
    "        d_node= np.random.randint(len(nodes_to_code.keys()))\n",
    "\n",
    "        edge_is_new= (len(edges_[(edges_[:,0]==o_node) & (edges_[:,1]==d_node)])==0)\n",
    "        \n",
    "        #If the (o_node, d_node) tuple already exists, try again...\n",
    "        while not edge_is_new:\n",
    "            d_node= np.random.randint(len(nodes_to_code.keys()))\n",
    "        \n",
    "            edge_is_new= (len(edges_[(edges_[:,0]==o_node) & (edges_[:,1]==d_node)])==0)\n",
    "\n",
    "        origins.append(o_node)\n",
    "        dest.append(d_node)\n",
    "        \n",
    "    edge_index_negs = torch.row_stack([torch.LongTensor(origins), torch.LongTensor(dest)])\n",
    "    return edge_index_negs\n",
    "\n",
    "def one_hot(array):\n",
    "    unique, inverse = np.unique(array, return_inverse=True)\n",
    "    onehot = np.eye(unique.shape[0])[inverse]\n",
    "    return torch.Tensor(onehot)\n",
    "\n",
    "def get_labels_for_edges(edges_subset, all_edges, all_labels):\n",
    "    \n",
    "    edges_subset_array= edges_subset.numpy()\n",
    "    edges_subset_array= np.stack(edges_subset_array).T\n",
    "    \n",
    "    a= all_edges.numpy()\n",
    "    a=np.stack(a).T\n",
    "\n",
    "    locations = [np.where((a[:,0]==o) & (a[:,1]==d)) for (o,d) in edges_subset_array]\n",
    "    #print(all_labels)\n",
    "    location_lst= [l[0][0] for l in locations]\n",
    "    \n",
    "    return all_labels[location_lst]\n",
    "\n",
    "def predict_scores(edge_index, embs):\n",
    "    scores = embs[edge_index[0,:], :] * embs[edge_index[1,:], :] # taking dot product for each playlist/song pair\n",
    "    scores = scores.sum(dim=1)\n",
    "    scores = torch.sigmoid(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_dataset, T, device, GNN_type='regular', max_snapshots=None):\n",
    "    \n",
    "    model = RecurrentGCN(node_features = 5, periods= 7)\n",
    "     \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    neg_edges_rate=1\n",
    "    n_epochs=40\n",
    "\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    batch_size= 10\n",
    "\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 6\n",
    "    trigger_times = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    snapshots_dict= dict((i,j) for i,j in enumerate(train_dataset))\n",
    "    time_steps= np.sort(list(snapshots_dict.keys()))\n",
    "\n",
    "    T=1 #Time horizon\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    #torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    range_low_limit=0\n",
    "    n_timestamps = len(time_steps)\n",
    "    if max_snapshots:\n",
    "        range_low_limit=max_snapshots\n",
    "        n_timestamps = max_snapshots\n",
    "        \n",
    "    print(f\"The number of timesteps for training is {n_timestamps}\")\n",
    "\n",
    "    #for epoch in tqdm(range(n_epochs), desc='Epochs...', leave=False):\n",
    "    for epoch in range(n_epochs):\n",
    "        #torch.cuda.empty_cache()\n",
    "        cost =0\n",
    "        node_embeddings = None\n",
    "        h= None\n",
    "        counter= 1\n",
    "        batch_loss = 0\n",
    "        last_t = 0\n",
    "        #the_current_loss = 0\n",
    "        #for t in tqdm(time_steps[:-T], desc='Time steps...', leave=False):\n",
    "        for t in time_steps[-(range_low_limit+T):-T]:\n",
    "            \n",
    "            train_snapshot = snapshots_dict[t].to(device)\n",
    "            target_snapshot = snapshots_dict[t+T]\n",
    "            \n",
    "            #Generate embeddings from the present graph\n",
    "            node_embeddings, h= model(train_snapshot.x, \n",
    "                                      train_snapshot.edge_index, \n",
    "                                      train_snapshot.edge_attr,          \n",
    "                                      h)\n",
    "\n",
    "            transform = RandomLinkSplit(is_undirected=False, add_negative_train_samples=False, neg_sampling_ratio=0,\n",
    "                                        num_val=0.15, num_test=0)\n",
    "\n",
    "            train_split, val_split, _ = transform(target_snapshot)\n",
    "\n",
    "            #Extract labels for positive edges and generate \"non-exist\" labels for the negative labels\n",
    "            pos_edges = train_split.edge_index\n",
    "\n",
    "            #Calculate train loss\n",
    "            #Genereate negative labels by considering the target graph at t+T \n",
    "            neg_edges_to_sample = int(pos_edges.shape[1]*neg_edges_rate)\n",
    "            neg_edges = sample_negative_edges(pos_edges, nodes_to_code, neg_edges_to_sample)\n",
    "\n",
    "            pos_scores= predict_scores(pos_edges, node_embeddings)\n",
    "            neg_scores= predict_scores(neg_edges, node_embeddings)\n",
    "\n",
    "            all_scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "            all_labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])], dim=0)\n",
    "\n",
    "            #print(node_embeddings, all_scores, all_labels)\n",
    "            loss = loss_fn(all_scores.to(device), all_labels.to(device))\n",
    "            cost = cost + loss\n",
    "            \"\"\"\n",
    "            #Calculate validation loss for early stopping\n",
    "            val_loss=0\n",
    "            with torch.no_grad():\n",
    "                neg_edges_to_sample = int(val_split.edge_index.shape[1]*neg_edges_rate) #100% of negative edges\n",
    "                neg_edges = sample_negative_edges(val_split.edge_index, nodes_to_code, neg_edges_to_sample)\n",
    "\n",
    "                pos_scores= predict_scores(val_split.edge_index, node_embeddings)\n",
    "                neg_scores= predict_scores(neg_edges, node_embeddings)\n",
    "\n",
    "                all_scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "                all_labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])], dim=0)\n",
    "\n",
    "                val_loss = loss_fn(all_scores.to(device), all_labels.to(device))\n",
    "\n",
    "            the_current_loss = the_current_loss + val_loss\n",
    "            \"\"\"\n",
    "\n",
    "            batch_loss = batch_loss + loss\n",
    "            if counter == batch_size:\n",
    "                batch_loss = batch_loss / batch_size\n",
    "                batch_loss.backward(retain_graph=True)\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                counter=1\n",
    "                batch_loss= 0\n",
    "                h= None\n",
    "                last_t =t\n",
    "            else:\n",
    "                counter += 1\n",
    "            \n",
    "\n",
    "        cost = cost / n_timestamps  \n",
    "\n",
    "        \"\"\"\n",
    "        # Early stopping\n",
    "        \n",
    "        the_current_loss= the_current_loss / n_timestamps\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            #print('Early stopping::trigger times:', trigger_times, end=' ')\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "        else:\n",
    "            #print('Early stopping::trigger times: 0', end=' ')\n",
    "            trigger_times = 0\n",
    "\n",
    "        the_last_loss = the_current_loss\n",
    "        \"\"\"\n",
    "        if counter > 1:\n",
    "            batch_loss= batch_loss / counter\n",
    "            batch_loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        #print(\"Average training & evaluation losses at epoch {} are {:.3f}, {:.3f}\".format(epoch, cost, the_current_loss))\n",
    "        print(\"Average training loss at epoch {} is {:.3f}\".format(epoch, cost))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, T, device, GNN_type, max_snapshots=None, eval_dates=None):\n",
    "    model.eval()\n",
    "\n",
    "    snapshots_dict= dict((i,j) for i,j in enumerate(test_dataset))\n",
    "    time_steps= np.sort(list(snapshots_dict.keys()))\n",
    "\n",
    "    y_true_all =[]\n",
    "    y_hat_all= []\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    h, c= None, None\n",
    "    \n",
    "    #for t in tqdm(time_steps[:-T], desc='Evaluation timesteps...'):\n",
    "    for t in time_steps[:-T]:\n",
    "\n",
    "        input_snapshot = snapshots_dict[t].to(device)\n",
    "        target_snapshot = snapshots_dict[t+T].to(device)\n",
    "\n",
    "        transform = RandomLinkSplit(is_undirected=False, add_negative_train_samples=False, neg_sampling_ratio=0,\n",
    "                                        num_val=0.15, num_test=0)\n",
    "\n",
    "        #train_split, val_split, _ = transform(target_snapshot)\n",
    "\n",
    "        embeddings, h= model(input_snapshot.x, input_snapshot.edge_index, input_snapshot.edge_attr,h)\n",
    "        \n",
    "        neg_edges_to_sample = int(target_snapshot.edge_index.shape[1]*1) #100% of negative edges\n",
    "        neg_edges = sample_negative_edges(target_snapshot.edge_index, nodes_to_code, neg_edges_to_sample)\n",
    "\n",
    "        pos_scores= predict_scores(target_snapshot.edge_index, embeddings)\n",
    "        neg_scores= predict_scores(neg_edges, embeddings)\n",
    "\n",
    "        all_labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])], dim=0)\n",
    "\n",
    "        #print(target_snapshot.edge_index.T.shape, neg_edges.T.shape)\n",
    "        all_scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "        all_labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])], dim=0)\n",
    "        all_edges = torch.vstack([target_snapshot.edge_index.T.cpu(), neg_edges.T.cpu()])\n",
    "        #print(all_edges.shape, all_labels.shape)\n",
    "        edges_and_scores = torch.hstack((all_scores.reshape(-1,1).cpu(),  all_edges.cpu(), all_labels.reshape(-1,1))).cpu().detach().numpy()    \n",
    "        result_df = pd.DataFrame(edges_and_scores, columns='score origin dest true_label'.split())\n",
    "        result_df['label_hat']= result_df['score'].apply(lambda v: 1.0 if v>0.5 else 0.0)\n",
    "        \n",
    "        if not eval_dates is None:\n",
    "            result_df['date']= eval_dates[t]\n",
    "        \n",
    "        results.append(result_df)\n",
    "        \n",
    "        if max_snapshots:\n",
    "            if t>= max_snapshots:\n",
    "                break\n",
    "        \n",
    "    all_results = pd.concat(results, axis=0)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device_ = \"cpu\" #torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\") \n",
    "max_snapshots_=40\n",
    "for gnn_type in tqdm(['tour_infras_totals_twt'], desc='GNN type...'):\n",
    "    for trip_type in tqdm(['high'], desc='Edge type...', leave=False):\n",
    "        include_twt_=False\n",
    "        gnn_type_for_loader = gnn_type\n",
    "        if gnn_type== 'tour_infras_totals_twt':\n",
    "            include_twt_=True\n",
    "            gnn_type_for_loader= 'tour_infras_totals'\n",
    "        loader= TouristMobDynamicDatasetLoader(target_slice=trip_type, edges_type= gnn_type_for_loader, include_twt=include_twt_)\n",
    "        dataset=loader.get_dataset()\n",
    "        train_dataset, test_dataset = temporal_signal_split(dataset,  train_ratio=0.8)\n",
    "        for T_ in tqdm([7,14,21], desc='Time horizon (days)', leave=False):\n",
    "            model_fitted = train(train_dataset, T_, device_, GNN_type=gnn_type, max_snapshots=max_snapshots_)\n",
    "            eval_results = evaluate(model_fitted, test_dataset, T_, device_, GNN_type=gnn_type, max_snapshots=max_snapshots_)\n",
    "            eval_results.to_csv(os.path.join('results', f'eval_results_{gnn_type}_{trip_type}_{T_}_{max_snapshots_}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case results generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_flows= pd.read_csv(os.path.join(data_path,'agg_flows_with.csv'), index_col=0, parse_dates=['timestamp'])\n",
    "tour_flows = tour_flows.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origen</th>\n",
       "      <th>destino</th>\n",
       "      <th>viajes</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>origin_dest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001_AM</td>\n",
       "      <td>06060_AM</td>\n",
       "      <td>3.841</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>01001_AM_06060_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001_AM</td>\n",
       "      <td>09056</td>\n",
       "      <td>10.800</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>01001_AM_09056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001_AM</td>\n",
       "      <td>09059</td>\n",
       "      <td>27.477</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>01001_AM_09059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001_AM</td>\n",
       "      <td>09194_AM</td>\n",
       "      <td>38.666</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>01001_AM_09194_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01001_AM</td>\n",
       "      <td>09439_AM</td>\n",
       "      <td>10.795</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>01001_AM_09439_AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         origen   destino  viajes  timestamp        origin_dest\n",
       "index                                                          \n",
       "0      01001_AM  06060_AM   3.841 2020-04-01  01001_AM_06060_AM\n",
       "1      01001_AM     09056  10.800 2020-04-01     01001_AM_09056\n",
       "2      01001_AM     09059  27.477 2020-04-01     01001_AM_09059\n",
       "3      01001_AM  09194_AM  38.666 2020-04-01  01001_AM_09194_AM\n",
       "4      01001_AM  09439_AM  10.795 2020-04-01  01001_AM_09439_AM"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tour_flows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-04-01T00:00:00.000000000', '2020-04-02T00:00:00.000000000',\n",
       "       '2020-04-03T00:00:00.000000000', '2020-04-04T00:00:00.000000000',\n",
       "       '2020-04-05T00:00:00.000000000', '2020-04-06T00:00:00.000000000',\n",
       "       '2020-04-07T00:00:00.000000000', '2020-04-08T00:00:00.000000000',\n",
       "       '2020-04-09T00:00:00.000000000', '2020-04-10T00:00:00.000000000',\n",
       "       '2020-04-11T00:00:00.000000000', '2020-04-12T00:00:00.000000000',\n",
       "       '2020-04-13T00:00:00.000000000', '2020-04-14T00:00:00.000000000',\n",
       "       '2020-04-15T00:00:00.000000000', '2020-04-16T00:00:00.000000000',\n",
       "       '2020-04-17T00:00:00.000000000', '2020-04-18T00:00:00.000000000',\n",
       "       '2020-04-19T00:00:00.000000000', '2020-04-20T00:00:00.000000000',\n",
       "       '2020-04-21T00:00:00.000000000', '2020-04-22T00:00:00.000000000',\n",
       "       '2020-04-23T00:00:00.000000000', '2020-04-24T00:00:00.000000000',\n",
       "       '2020-04-25T00:00:00.000000000', '2020-04-26T00:00:00.000000000',\n",
       "       '2020-04-27T00:00:00.000000000', '2020-04-28T00:00:00.000000000',\n",
       "       '2020-04-29T00:00:00.000000000', '2020-04-30T00:00:00.000000000',\n",
       "       '2020-05-01T00:00:00.000000000', '2020-05-02T00:00:00.000000000',\n",
       "       '2020-05-03T00:00:00.000000000', '2020-05-04T00:00:00.000000000',\n",
       "       '2020-05-05T00:00:00.000000000', '2020-05-06T00:00:00.000000000',\n",
       "       '2020-05-07T00:00:00.000000000', '2020-05-08T00:00:00.000000000',\n",
       "       '2020-05-09T00:00:00.000000000', '2020-05-10T00:00:00.000000000',\n",
       "       '2020-05-11T00:00:00.000000000', '2020-05-12T00:00:00.000000000',\n",
       "       '2020-05-13T00:00:00.000000000', '2020-05-14T00:00:00.000000000',\n",
       "       '2020-05-15T00:00:00.000000000', '2020-05-16T00:00:00.000000000',\n",
       "       '2020-05-17T00:00:00.000000000', '2020-05-18T00:00:00.000000000',\n",
       "       '2020-05-19T00:00:00.000000000', '2020-05-20T00:00:00.000000000',\n",
       "       '2020-05-21T00:00:00.000000000', '2020-05-22T00:00:00.000000000',\n",
       "       '2020-05-23T00:00:00.000000000', '2020-05-24T00:00:00.000000000',\n",
       "       '2020-05-25T00:00:00.000000000', '2020-05-26T00:00:00.000000000',\n",
       "       '2020-05-27T00:00:00.000000000', '2020-05-28T00:00:00.000000000',\n",
       "       '2020-05-29T00:00:00.000000000', '2020-05-30T00:00:00.000000000',\n",
       "       '2020-05-31T00:00:00.000000000', '2020-06-01T00:00:00.000000000',\n",
       "       '2020-06-02T00:00:00.000000000', '2020-06-03T00:00:00.000000000',\n",
       "       '2020-06-04T00:00:00.000000000', '2020-06-05T00:00:00.000000000',\n",
       "       '2020-06-06T00:00:00.000000000', '2020-06-07T00:00:00.000000000',\n",
       "       '2020-06-08T00:00:00.000000000', '2020-06-09T00:00:00.000000000',\n",
       "       '2020-06-10T00:00:00.000000000', '2020-06-11T00:00:00.000000000',\n",
       "       '2020-06-12T00:00:00.000000000', '2020-06-13T00:00:00.000000000',\n",
       "       '2020-06-14T00:00:00.000000000', '2020-06-15T00:00:00.000000000',\n",
       "       '2020-06-16T00:00:00.000000000', '2020-06-17T00:00:00.000000000',\n",
       "       '2020-06-18T00:00:00.000000000', '2020-06-19T00:00:00.000000000',\n",
       "       '2020-06-20T00:00:00.000000000', '2020-06-21T00:00:00.000000000',\n",
       "       '2020-06-22T00:00:00.000000000', '2020-06-23T00:00:00.000000000',\n",
       "       '2020-06-24T00:00:00.000000000', '2020-06-25T00:00:00.000000000',\n",
       "       '2020-06-26T00:00:00.000000000', '2020-06-27T00:00:00.000000000',\n",
       "       '2020-06-28T00:00:00.000000000', '2020-06-29T00:00:00.000000000',\n",
       "       '2020-06-30T00:00:00.000000000', '2020-07-01T00:00:00.000000000',\n",
       "       '2020-07-02T00:00:00.000000000', '2020-07-03T00:00:00.000000000',\n",
       "       '2020-07-04T00:00:00.000000000', '2020-07-05T00:00:00.000000000',\n",
       "       '2020-07-06T00:00:00.000000000', '2020-07-07T00:00:00.000000000',\n",
       "       '2020-07-08T00:00:00.000000000', '2020-07-09T00:00:00.000000000',\n",
       "       '2020-07-10T00:00:00.000000000', '2020-07-11T00:00:00.000000000',\n",
       "       '2020-07-12T00:00:00.000000000', '2020-07-13T00:00:00.000000000',\n",
       "       '2020-07-14T00:00:00.000000000', '2020-07-15T00:00:00.000000000',\n",
       "       '2020-07-16T00:00:00.000000000', '2020-07-17T00:00:00.000000000',\n",
       "       '2020-07-18T00:00:00.000000000', '2020-07-19T00:00:00.000000000',\n",
       "       '2020-07-20T00:00:00.000000000', '2020-07-21T00:00:00.000000000',\n",
       "       '2020-07-22T00:00:00.000000000', '2020-07-23T00:00:00.000000000',\n",
       "       '2020-07-24T00:00:00.000000000', '2020-07-25T00:00:00.000000000',\n",
       "       '2020-07-26T00:00:00.000000000', '2020-07-27T00:00:00.000000000',\n",
       "       '2020-07-28T00:00:00.000000000', '2020-07-29T00:00:00.000000000',\n",
       "       '2020-07-30T00:00:00.000000000', '2020-07-31T00:00:00.000000000',\n",
       "       '2020-08-01T00:00:00.000000000', '2020-08-02T00:00:00.000000000',\n",
       "       '2020-08-03T00:00:00.000000000', '2020-08-04T00:00:00.000000000',\n",
       "       '2020-08-05T00:00:00.000000000', '2020-08-06T00:00:00.000000000',\n",
       "       '2020-08-07T00:00:00.000000000', '2020-08-08T00:00:00.000000000',\n",
       "       '2020-08-09T00:00:00.000000000', '2020-08-10T00:00:00.000000000',\n",
       "       '2020-08-11T00:00:00.000000000', '2020-08-12T00:00:00.000000000',\n",
       "       '2020-08-13T00:00:00.000000000', '2020-08-14T00:00:00.000000000',\n",
       "       '2020-08-15T00:00:00.000000000', '2020-08-16T00:00:00.000000000',\n",
       "       '2020-08-17T00:00:00.000000000', '2020-08-18T00:00:00.000000000',\n",
       "       '2020-08-19T00:00:00.000000000', '2020-08-20T00:00:00.000000000',\n",
       "       '2020-08-21T00:00:00.000000000', '2020-08-22T00:00:00.000000000',\n",
       "       '2020-08-23T00:00:00.000000000', '2020-08-24T00:00:00.000000000',\n",
       "       '2020-08-25T00:00:00.000000000', '2020-08-26T00:00:00.000000000',\n",
       "       '2020-08-27T00:00:00.000000000', '2020-08-28T00:00:00.000000000',\n",
       "       '2020-08-29T00:00:00.000000000', '2020-08-30T00:00:00.000000000',\n",
       "       '2020-08-31T00:00:00.000000000', '2020-09-01T00:00:00.000000000',\n",
       "       '2020-09-02T00:00:00.000000000', '2020-09-03T00:00:00.000000000',\n",
       "       '2020-09-04T00:00:00.000000000', '2020-09-05T00:00:00.000000000',\n",
       "       '2020-09-06T00:00:00.000000000', '2020-09-07T00:00:00.000000000',\n",
       "       '2020-09-08T00:00:00.000000000', '2020-09-09T00:00:00.000000000',\n",
       "       '2020-09-10T00:00:00.000000000', '2020-09-11T00:00:00.000000000',\n",
       "       '2020-09-12T00:00:00.000000000', '2020-09-13T00:00:00.000000000',\n",
       "       '2020-09-14T00:00:00.000000000', '2020-09-15T00:00:00.000000000',\n",
       "       '2020-09-16T00:00:00.000000000', '2020-09-17T00:00:00.000000000',\n",
       "       '2020-09-18T00:00:00.000000000', '2020-09-19T00:00:00.000000000',\n",
       "       '2020-09-20T00:00:00.000000000', '2020-09-21T00:00:00.000000000',\n",
       "       '2020-09-22T00:00:00.000000000', '2020-09-23T00:00:00.000000000',\n",
       "       '2020-09-24T00:00:00.000000000', '2020-09-25T00:00:00.000000000',\n",
       "       '2020-09-26T00:00:00.000000000', '2020-09-27T00:00:00.000000000',\n",
       "       '2020-09-28T00:00:00.000000000', '2020-09-29T00:00:00.000000000',\n",
       "       '2020-09-30T00:00:00.000000000', '2020-10-01T00:00:00.000000000',\n",
       "       '2020-10-02T00:00:00.000000000', '2020-10-03T00:00:00.000000000',\n",
       "       '2020-10-04T00:00:00.000000000', '2020-10-05T00:00:00.000000000',\n",
       "       '2020-10-06T00:00:00.000000000', '2020-10-07T00:00:00.000000000',\n",
       "       '2020-10-08T00:00:00.000000000', '2020-10-09T00:00:00.000000000',\n",
       "       '2020-10-10T00:00:00.000000000', '2020-10-11T00:00:00.000000000',\n",
       "       '2020-10-12T00:00:00.000000000', '2020-10-13T00:00:00.000000000',\n",
       "       '2020-10-14T00:00:00.000000000', '2020-10-15T00:00:00.000000000',\n",
       "       '2020-10-16T00:00:00.000000000', '2020-10-17T00:00:00.000000000',\n",
       "       '2020-10-18T00:00:00.000000000', '2020-10-19T00:00:00.000000000',\n",
       "       '2020-10-20T00:00:00.000000000', '2020-10-21T00:00:00.000000000',\n",
       "       '2020-10-22T00:00:00.000000000', '2020-10-23T00:00:00.000000000',\n",
       "       '2020-10-24T00:00:00.000000000', '2020-10-25T00:00:00.000000000',\n",
       "       '2020-10-26T00:00:00.000000000', '2020-10-27T00:00:00.000000000',\n",
       "       '2020-10-28T00:00:00.000000000', '2020-10-29T00:00:00.000000000',\n",
       "       '2020-10-30T00:00:00.000000000', '2020-10-31T00:00:00.000000000',\n",
       "       '2020-11-01T00:00:00.000000000', '2020-11-02T00:00:00.000000000',\n",
       "       '2020-11-03T00:00:00.000000000', '2020-11-04T00:00:00.000000000',\n",
       "       '2020-11-05T00:00:00.000000000', '2020-11-06T00:00:00.000000000',\n",
       "       '2020-11-07T00:00:00.000000000', '2020-11-08T00:00:00.000000000',\n",
       "       '2020-11-09T00:00:00.000000000', '2020-11-10T00:00:00.000000000',\n",
       "       '2020-11-11T00:00:00.000000000', '2020-11-12T00:00:00.000000000',\n",
       "       '2020-11-13T00:00:00.000000000', '2020-11-14T00:00:00.000000000',\n",
       "       '2020-11-15T00:00:00.000000000', '2020-11-16T00:00:00.000000000',\n",
       "       '2020-11-17T00:00:00.000000000', '2020-11-18T00:00:00.000000000',\n",
       "       '2020-11-19T00:00:00.000000000', '2020-11-20T00:00:00.000000000',\n",
       "       '2020-11-21T00:00:00.000000000', '2020-11-22T00:00:00.000000000',\n",
       "       '2020-11-23T00:00:00.000000000', '2020-11-24T00:00:00.000000000',\n",
       "       '2020-11-25T00:00:00.000000000', '2020-11-26T00:00:00.000000000',\n",
       "       '2020-11-27T00:00:00.000000000', '2020-11-28T00:00:00.000000000',\n",
       "       '2020-11-29T00:00:00.000000000', '2020-11-30T00:00:00.000000000',\n",
       "       '2020-12-01T00:00:00.000000000', '2020-12-02T00:00:00.000000000',\n",
       "       '2020-12-03T00:00:00.000000000', '2020-12-04T00:00:00.000000000',\n",
       "       '2020-12-05T00:00:00.000000000', '2020-12-06T00:00:00.000000000',\n",
       "       '2020-12-07T00:00:00.000000000', '2020-12-08T00:00:00.000000000',\n",
       "       '2020-12-09T00:00:00.000000000', '2020-12-10T00:00:00.000000000',\n",
       "       '2020-12-11T00:00:00.000000000', '2020-12-12T00:00:00.000000000',\n",
       "       '2020-12-13T00:00:00.000000000', '2020-12-14T00:00:00.000000000',\n",
       "       '2020-12-15T00:00:00.000000000', '2020-12-16T00:00:00.000000000',\n",
       "       '2020-12-17T00:00:00.000000000', '2020-12-18T00:00:00.000000000',\n",
       "       '2020-12-19T00:00:00.000000000', '2020-12-20T00:00:00.000000000',\n",
       "       '2020-12-21T00:00:00.000000000', '2020-12-22T00:00:00.000000000',\n",
       "       '2020-12-23T00:00:00.000000000', '2020-12-24T00:00:00.000000000',\n",
       "       '2020-12-25T00:00:00.000000000', '2020-12-26T00:00:00.000000000',\n",
       "       '2020-12-27T00:00:00.000000000', '2020-12-28T00:00:00.000000000',\n",
       "       '2020-12-29T00:00:00.000000000', '2020-12-30T00:00:00.000000000',\n",
       "       '2020-12-31T00:00:00.000000000', '2021-01-01T00:00:00.000000000',\n",
       "       '2021-01-02T00:00:00.000000000', '2021-01-03T00:00:00.000000000',\n",
       "       '2021-01-04T00:00:00.000000000', '2021-01-05T00:00:00.000000000',\n",
       "       '2021-01-06T00:00:00.000000000', '2021-01-07T00:00:00.000000000',\n",
       "       '2021-01-08T00:00:00.000000000', '2021-01-09T00:00:00.000000000',\n",
       "       '2021-01-10T00:00:00.000000000', '2021-01-11T00:00:00.000000000',\n",
       "       '2021-01-12T00:00:00.000000000', '2021-01-13T00:00:00.000000000',\n",
       "       '2021-01-14T00:00:00.000000000', '2021-01-15T00:00:00.000000000',\n",
       "       '2021-01-16T00:00:00.000000000', '2021-01-17T00:00:00.000000000',\n",
       "       '2021-01-18T00:00:00.000000000', '2021-01-19T00:00:00.000000000',\n",
       "       '2021-01-20T00:00:00.000000000', '2021-01-21T00:00:00.000000000',\n",
       "       '2021-01-22T00:00:00.000000000', '2021-01-23T00:00:00.000000000',\n",
       "       '2021-01-24T00:00:00.000000000', '2021-01-25T00:00:00.000000000',\n",
       "       '2021-01-26T00:00:00.000000000', '2021-01-27T00:00:00.000000000',\n",
       "       '2021-01-28T00:00:00.000000000', '2021-01-29T00:00:00.000000000',\n",
       "       '2021-01-30T00:00:00.000000000', '2021-01-31T00:00:00.000000000',\n",
       "       '2021-02-01T00:00:00.000000000', '2021-02-02T00:00:00.000000000',\n",
       "       '2021-02-03T00:00:00.000000000', '2021-02-04T00:00:00.000000000',\n",
       "       '2021-02-05T00:00:00.000000000', '2021-02-06T00:00:00.000000000',\n",
       "       '2021-02-07T00:00:00.000000000', '2021-02-08T00:00:00.000000000',\n",
       "       '2021-02-09T00:00:00.000000000', '2021-02-10T00:00:00.000000000',\n",
       "       '2021-02-11T00:00:00.000000000', '2021-02-12T00:00:00.000000000',\n",
       "       '2021-02-13T00:00:00.000000000', '2021-02-14T00:00:00.000000000',\n",
       "       '2021-02-15T00:00:00.000000000', '2021-02-16T00:00:00.000000000',\n",
       "       '2021-02-17T00:00:00.000000000', '2021-02-18T00:00:00.000000000',\n",
       "       '2021-02-19T00:00:00.000000000', '2021-02-20T00:00:00.000000000',\n",
       "       '2021-02-21T00:00:00.000000000', '2021-02-22T00:00:00.000000000',\n",
       "       '2021-02-23T00:00:00.000000000', '2021-02-24T00:00:00.000000000',\n",
       "       '2021-02-25T00:00:00.000000000', '2021-02-26T00:00:00.000000000',\n",
       "       '2021-02-27T00:00:00.000000000', '2021-02-28T00:00:00.000000000',\n",
       "       '2021-03-01T00:00:00.000000000', '2021-03-02T00:00:00.000000000',\n",
       "       '2021-03-03T00:00:00.000000000', '2021-03-04T00:00:00.000000000',\n",
       "       '2021-03-05T00:00:00.000000000', '2021-03-06T00:00:00.000000000',\n",
       "       '2021-03-07T00:00:00.000000000', '2021-03-08T00:00:00.000000000',\n",
       "       '2021-03-09T00:00:00.000000000', '2021-03-10T00:00:00.000000000',\n",
       "       '2021-03-11T00:00:00.000000000', '2021-03-12T00:00:00.000000000',\n",
       "       '2021-03-13T00:00:00.000000000', '2021-03-14T00:00:00.000000000',\n",
       "       '2021-03-15T00:00:00.000000000', '2021-03-16T00:00:00.000000000',\n",
       "       '2021-03-17T00:00:00.000000000', '2021-03-18T00:00:00.000000000',\n",
       "       '2021-03-19T00:00:00.000000000', '2021-03-20T00:00:00.000000000',\n",
       "       '2021-03-21T00:00:00.000000000', '2021-03-22T00:00:00.000000000',\n",
       "       '2021-03-23T00:00:00.000000000', '2021-03-24T00:00:00.000000000',\n",
       "       '2021-03-25T00:00:00.000000000', '2021-03-26T00:00:00.000000000',\n",
       "       '2021-03-27T00:00:00.000000000', '2021-03-28T00:00:00.000000000',\n",
       "       '2021-03-29T00:00:00.000000000', '2021-03-30T00:00:00.000000000',\n",
       "       '2021-03-31T00:00:00.000000000', '2021-04-01T00:00:00.000000000',\n",
       "       '2021-04-02T00:00:00.000000000', '2021-04-03T00:00:00.000000000',\n",
       "       '2021-04-04T00:00:00.000000000', '2021-04-05T00:00:00.000000000',\n",
       "       '2021-04-06T00:00:00.000000000', '2021-04-07T00:00:00.000000000',\n",
       "       '2021-04-08T00:00:00.000000000', '2021-04-09T00:00:00.000000000',\n",
       "       '2021-04-10T00:00:00.000000000', '2021-04-11T00:00:00.000000000',\n",
       "       '2021-04-12T00:00:00.000000000', '2021-04-13T00:00:00.000000000',\n",
       "       '2021-04-14T00:00:00.000000000', '2021-04-15T00:00:00.000000000',\n",
       "       '2021-04-16T00:00:00.000000000', '2021-04-17T00:00:00.000000000',\n",
       "       '2021-04-18T00:00:00.000000000', '2021-04-19T00:00:00.000000000',\n",
       "       '2021-04-20T00:00:00.000000000', '2021-04-21T00:00:00.000000000',\n",
       "       '2021-04-22T00:00:00.000000000', '2021-04-23T00:00:00.000000000',\n",
       "       '2021-04-24T00:00:00.000000000', '2021-04-25T00:00:00.000000000',\n",
       "       '2021-04-26T00:00:00.000000000', '2021-04-27T00:00:00.000000000',\n",
       "       '2021-04-28T00:00:00.000000000', '2021-04-29T00:00:00.000000000',\n",
       "       '2021-04-30T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days= tour_flows['timestamp'].sort_values(ascending=True).unique()\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316.0, 79.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(days)*0.8, len(days)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dates_ = days[317:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49969e4f1a64d308a4edea554c82259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GNN type...:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de730abdf42946c7b95d73d2f122be8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Edge type...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Time horizon (days):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of timesteps for training is 40\n",
      "Average training loss at epoch 0 is 0.727\n",
      "Average training loss at epoch 1 is 0.692\n",
      "Average training loss at epoch 2 is 0.684\n",
      "Average training loss at epoch 3 is 0.675\n",
      "Average training loss at epoch 4 is 0.677\n",
      "Average training loss at epoch 5 is 0.671\n",
      "Average training loss at epoch 6 is 0.671\n",
      "Average training loss at epoch 7 is 0.660\n",
      "Average training loss at epoch 8 is 0.652\n",
      "Average training loss at epoch 9 is 0.655\n",
      "Average training loss at epoch 10 is 0.649\n",
      "Average training loss at epoch 11 is 0.648\n",
      "Average training loss at epoch 12 is 0.646\n",
      "Average training loss at epoch 13 is 0.646\n",
      "Average training loss at epoch 14 is 0.646\n",
      "Average training loss at epoch 15 is 0.642\n",
      "Average training loss at epoch 16 is 0.638\n",
      "Average training loss at epoch 17 is 0.641\n",
      "Average training loss at epoch 18 is 0.641\n",
      "Average training loss at epoch 19 is 0.644\n",
      "Average training loss at epoch 20 is 0.635\n",
      "Average training loss at epoch 21 is 0.635\n",
      "Average training loss at epoch 22 is 0.638\n",
      "Average training loss at epoch 23 is 0.644\n",
      "Average training loss at epoch 24 is 0.643\n",
      "Average training loss at epoch 25 is 0.634\n",
      "Average training loss at epoch 26 is 0.637\n",
      "Average training loss at epoch 27 is 0.635\n",
      "Average training loss at epoch 28 is 0.629\n",
      "Average training loss at epoch 29 is 0.628\n",
      "Average training loss at epoch 30 is 0.634\n",
      "Average training loss at epoch 31 is 0.631\n",
      "Average training loss at epoch 32 is 0.636\n",
      "Average training loss at epoch 33 is 0.626\n",
      "Average training loss at epoch 34 is 0.627\n",
      "Average training loss at epoch 35 is 0.630\n",
      "Average training loss at epoch 36 is 0.636\n",
      "Average training loss at epoch 37 is 0.630\n",
      "Average training loss at epoch 38 is 0.626\n",
      "Average training loss at epoch 39 is 0.633\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Time horizon (days):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of timesteps for training is 40\n",
      "Average training loss at epoch 0 is 0.683\n",
      "Average training loss at epoch 1 is 0.663\n",
      "Average training loss at epoch 2 is 0.660\n",
      "Average training loss at epoch 3 is 0.662\n",
      "Average training loss at epoch 4 is 0.656\n",
      "Average training loss at epoch 5 is 0.663\n",
      "Average training loss at epoch 6 is 0.650\n",
      "Average training loss at epoch 7 is 0.648\n",
      "Average training loss at epoch 8 is 0.645\n",
      "Average training loss at epoch 9 is 0.641\n",
      "Average training loss at epoch 10 is 0.643\n",
      "Average training loss at epoch 11 is 0.651\n",
      "Average training loss at epoch 12 is 0.642\n",
      "Average training loss at epoch 13 is 0.641\n",
      "Average training loss at epoch 14 is 0.636\n",
      "Average training loss at epoch 15 is 0.632\n",
      "Average training loss at epoch 16 is 0.630\n",
      "Average training loss at epoch 17 is 0.630\n",
      "Average training loss at epoch 18 is 0.639\n",
      "Average training loss at epoch 19 is 0.640\n",
      "Average training loss at epoch 20 is 0.648\n",
      "Average training loss at epoch 21 is 0.635\n",
      "Average training loss at epoch 22 is 0.632\n",
      "Average training loss at epoch 23 is 0.642\n",
      "Average training loss at epoch 24 is 0.634\n",
      "Average training loss at epoch 25 is 0.631\n",
      "Average training loss at epoch 26 is 0.627\n",
      "Average training loss at epoch 27 is 0.632\n",
      "Average training loss at epoch 28 is 0.630\n",
      "Average training loss at epoch 29 is 0.625\n",
      "Average training loss at epoch 30 is 0.622\n",
      "Average training loss at epoch 31 is 0.625\n",
      "Average training loss at epoch 32 is 0.626\n",
      "Average training loss at epoch 33 is 0.627\n",
      "Average training loss at epoch 34 is 0.645\n",
      "Average training loss at epoch 35 is 0.661\n",
      "Average training loss at epoch 36 is 0.624\n",
      "Average training loss at epoch 37 is 0.620\n",
      "Average training loss at epoch 38 is 0.620\n",
      "Average training loss at epoch 39 is 0.626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d3c8b987d34c0a9ede143556463198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Time horizon (days):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of timesteps for training is 40\n",
      "Average training loss at epoch 0 is 0.693\n",
      "Average training loss at epoch 1 is 0.691\n",
      "Average training loss at epoch 2 is 0.679\n",
      "Average training loss at epoch 3 is 0.652\n",
      "Average training loss at epoch 4 is 0.643\n",
      "Average training loss at epoch 5 is 0.638\n",
      "Average training loss at epoch 6 is 0.643\n",
      "Average training loss at epoch 7 is 0.646\n",
      "Average training loss at epoch 8 is 0.647\n",
      "Average training loss at epoch 9 is 0.644\n",
      "Average training loss at epoch 10 is 0.645\n",
      "Average training loss at epoch 11 is 0.647\n",
      "Average training loss at epoch 12 is 0.648\n",
      "Average training loss at epoch 13 is 0.641\n",
      "Average training loss at epoch 14 is 0.640\n",
      "Average training loss at epoch 15 is 0.647\n",
      "Average training loss at epoch 16 is 0.640\n",
      "Average training loss at epoch 17 is 0.636\n",
      "Average training loss at epoch 18 is 0.648\n",
      "Average training loss at epoch 19 is 0.632\n",
      "Average training loss at epoch 20 is 0.629\n",
      "Average training loss at epoch 21 is 0.636\n",
      "Average training loss at epoch 22 is 0.618\n",
      "Average training loss at epoch 23 is 0.635\n",
      "Average training loss at epoch 24 is 0.645\n",
      "Average training loss at epoch 25 is 0.657\n",
      "Average training loss at epoch 26 is 0.629\n",
      "Average training loss at epoch 27 is 0.651\n",
      "Average training loss at epoch 28 is 0.633\n",
      "Average training loss at epoch 29 is 0.626\n",
      "Average training loss at epoch 30 is 0.639\n",
      "Average training loss at epoch 31 is 0.631\n",
      "Average training loss at epoch 32 is 0.627\n"
     ]
    }
   ],
   "source": [
    "device_ = \"cpu\"\n",
    "max_snapshots_=40\n",
    "for gnn_type in tqdm(['tour_infras_totals_twt'], desc='GNN type...'):\n",
    "    for trip_type in tqdm(['low', 'med', 'high'], desc='Edge type...', leave=False):\n",
    "        include_twt_=False\n",
    "        gnn_type_for_loader = gnn_type\n",
    "        if gnn_type== 'tour_infras_totals_twt':\n",
    "            include_twt_=True\n",
    "            gnn_type_for_loader= 'tour_infras_totals'\n",
    "        loader= TouristMobDynamicDatasetLoader(target_slice=trip_type, edges_type= gnn_type_for_loader, include_twt=include_twt_)\n",
    "        dataset=loader.get_dataset()\n",
    "        train_dataset, test_dataset = temporal_signal_split(dataset,  train_ratio=0.8)\n",
    "        \n",
    "        for T_ in tqdm([14], desc='Time horizon (days)', leave=False):\n",
    "            model_fitted = train(train_dataset, T_, device_, GNN_type=gnn_type, max_snapshots=max_snapshots_)\n",
    "            eval_results = evaluate(model_fitted, test_dataset, T_, device_, GNN_type=gnn_type, max_snapshots=max_snapshots_, eval_dates= eval_dates_)\n",
    "            eval_results.to_csv(os.path.join('results', f'use_case_results_{gnn_type}_{trip_type}_{T_}_{max_snapshots_}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That's all folks!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
